{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "train_pathology_path = 'data/train_pathology.csv'\n",
    "test_pathology_path = 'data/test_pathology.csv'\n",
    "train_plants_path = 'data/train_plants.csv'\n",
    "test_plants_path = 'data/test_plants.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_config(config_path = 'config.json'):\n",
    "    file = open(config_path,'r')\n",
    "    return json.load(file)\n",
    "\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf, tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import mkdir, listdir\n",
    "from os.path import exists, isfile, join\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.layers import Dense,BatchNormalization,Dropout,Input,Flatten,Activation,Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train,y_train, test_size = 0.2):\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size = test_size, random_state=0)\n",
    "    for train_index, test_index in sss.split(x_train, y_train):\n",
    "        x_train, x_test = x_train[train_index], x_train[test_index]\n",
    "        y_train, y_test = y_train[train_index], y_train[test_index]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(path):\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    paths = df.pop('path')\n",
    "    \n",
    "    paths = [str(elem) for elem in paths]\n",
    "    \n",
    "    y = df.to_numpy().astype('float32')\n",
    " \n",
    "    return np.array(paths),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pathology,y_train_pathology = get_train_data(train_pathology_path)\n",
    "x_train_plants,y_train_plants = get_train_data(train_plants_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pathology,y_train_pathology,x_val_pathology,y_val_pathology = train_val_split(x_train_pathology,y_train_pathology)\n",
    "\n",
    "x_train_plants,y_train_plants,x_val_plants,y_val_plants = train_val_split(x_train_plants,y_train_plants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "def load_model(model_path,weights_path):\n",
    "    \n",
    "    json_file = open(model_path, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(weights_path)\n",
    "\n",
    "    print(\"model loaded successfully\")\n",
    "    return loaded_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = config['img_height']\n",
    "img_width = config['img_width']\n",
    "epochs = config['epochs']\n",
    "batch_size = config['batch_size']\n",
    "\n",
    "need_training = config['need_training']\n",
    "\n",
    "model_name = config['model_name']\n",
    "model_json_path = config['model_json_path']\n",
    "model_weights_path = config['model_weights_path']\n",
    "\n",
    "nb_classes = y_train_pathology.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "def get_model():\n",
    "    '''\n",
    "    inp = Input(shape=(img_height,img_width,3))\n",
    "    x = Flatten()(inp)\n",
    "    x = Dense(nb_classes,activation='softmax')(x)\n",
    "    return Model(inp,x)\n",
    "    \n",
    "    '''\n",
    "    base_model = efn.EfficientNetB0(weights='imagenet',\n",
    "                              include_top=False,\n",
    "                              input_shape=(img_height,img_width, 3),\n",
    "                              pooling='avg')\n",
    "        \n",
    "    x = base_model.output\n",
    "    predictions = Dense(nb_classes,activation='softmax')(x)\n",
    "    \n",
    "    return Model(base_model.input,predictions)\n",
    "    \n",
    "    '''\n",
    "    base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3))\n",
    " \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "  \n",
    "    predictions = Dense(nb_classes, activation='softmax')(x)\n",
    " \n",
    "    return Model(inputs=base_model.input, outputs=predictions)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "if (model_json_path is None):\n",
    "    model = get_model()\n",
    "else:\n",
    "    model = load_model(model_json_path,model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing metrics\n",
    "\n",
    "if not exists('output'):\n",
    "    mkdir('output')\n",
    "    \n",
    "if not exists(join('output',model_name)):\n",
    "    mkdir(join('output',model_name))\n",
    "\n",
    "save_model_path = join('output',model_name,'model_weights.h5')\n",
    "\n",
    "MODEL_CFG = {\n",
    "    'optimizer': Adam(lr=0.001),\n",
    "    'loss': 'categorical_crossentropy',\n",
    "    'metrics': ['accuracy'],\n",
    "    'name': save_model_path\n",
    "}\n",
    "\n",
    "CL_BEST_MODEL= ModelCheckpoint(MODEL_CFG['name'], \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True,\n",
    "                                 save_weights_only=True,\n",
    "                                 mode='min')\n",
    "    \n",
    "CL_REDUCE_LR = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                  factor=0.5,\n",
    "                                  verbose=0,\n",
    "                                  min_lr = 1e-5,\n",
    "                                  patience=10)\n",
    "\n",
    "CL_EARLY_STOPPING = EarlyStopping(monitor = \"val_loss\" , verbose = 1 , mode = 'min' , patience = 50)\n",
    "\n",
    "CALLBACKS = [CL_BEST_MODEL,CL_REDUCE_LR,CL_EARLY_STOPPING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "            optimizer = MODEL_CFG['optimizer'],\n",
    "            loss = MODEL_CFG['loss'],\n",
    "            metrics = MODEL_CFG['metrics'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                train_generator,\n",
    "                val_generator = None,\n",
    "                epochs = 10,\n",
    "                steps = 22,\n",
    "                class_weights = None\n",
    "               ):\n",
    "\n",
    "    history = model.fit_generator(\n",
    "        generator = train_generator,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data = val_generator,\n",
    "        callbacks=CALLBACKS,\n",
    "        class_weight = class_weights\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataGenerator import DataGenerator\n",
    "\n",
    "gen_train = DataGenerator(x_train_pathology,y_train_pathology,batch_size,augment = config['do_augmentation'])\n",
    "\n",
    "gen_val = DataGenerator(x_val_pathology,y_val_pathology,batch_size,shuffle=False,augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = None\n",
    "if need_training:\n",
    "    history = train_model(model,gen_train,gen_val,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if history is not None:\n",
    "    history_path = join('output',model_name,'history')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(join('output',model_name,'model.json'), \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(join('output',model_name,'model_weights.h5'))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
